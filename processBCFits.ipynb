{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d191dce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/ajo5182/.conda/envs/xhcd/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.modeling import models, fitting\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "#from astropy.wcs import WCS\n",
    "import os\n",
    "#import scipy.stats as stats\n",
    "#import json\n",
    "import pandas as pd\n",
    "from fitsutil import *\n",
    "from bc_imaging_analysis import imaging_analysis\n",
    "from xraysky.scripts import events_imaging\n",
    "from bcpsf import *\n",
    "#from numba import jit\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b561f12",
   "metadata": {},
   "source": [
    "This one is for windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventPath = Path(\n",
    "    r\"Z:/Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\y2024-12-12\\BC057_Ti_FF_233_HORI_0_0\\Analysis\\imaging_analysis_20241213\\combined_events_th1_200.fits.gz\"\n",
    ")\n",
    "d = fits.open(eventPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventPath = Path(\n",
    "    r\"/mnt/z/Astro_BlackCAT/BlackCAT_Calibration_Data/LC_Calibration_Data/y2024-12-12/BC057_Ti_FF_233_HORI_0_0/Analysis/imaging_analysis_20241213/combined_events_th1_200.fits.gz\"\n",
    ")\n",
    "d = fits.open(eventPath)\n",
    "cols = d[1].columns\n",
    "(d[1].header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(d))\n",
    "evntlist_in_browser(eventPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal, trash = splitEventList(d,3020,\"sum\")\n",
    "signal, noiseShelf = splitEventList(d,550,\"sum\")\n",
    "noiseShelf.columns = cols\n",
    "noiseShelf.header = d[1].header\n",
    "noiseShelf.writeto(\"/home/laurel/astro/testing/noiseshelf.fits.gz\",overwrite=True)\n",
    "signal.columns = cols\n",
    "signal.header = d[1].header\n",
    "signal.writeto(\"/home/laurel/astro/testing/signal.fits.gz\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Spectrum(\"/home/laurel/astro/testing/noiseshelf.fits.gz\",th1 = 200, th2=60)\n",
    "noise.plotSpectrum(binsize=10)\n",
    "sig = Spectrum(\"/home/laurel/astro/testing/signal.fits.gz\",th1 = 200, th2=60)\n",
    "sig.plotSpectrum(binsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d644930",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = halfEventList(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_a = random_sample_events_list(a,1500)\n",
    "random_b = random_sample_events_list(b,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff006e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.array(noiseShelf.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbe5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_a.data = np.append(random_a.data,noiseShelf.data)\n",
    "print(len(random_a.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleHDU = fits.BinTableHDU.from_columns(cols)\n",
    "random_a.columns = cols\n",
    "random_a.header = d[1].header\n",
    "random_a.writeto(\"/home/laurel/astro/testing/test.fits.gz\",overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fits.open(\"/home/laurel/astro/testing/test.fits.gz\")\n",
    "test[1].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Spectrum(\"/home/laurel/astro/testing/test.fits.gz\",th1 = 200, th2=60)\n",
    "test.plotSpectrum(binsize=10)\n",
    "#out = test.filterEvents(sumrange=[0,550])\n",
    "#out.plotSpectrum(binsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e341fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imager= events_imaging.BC_Imaging()\n",
    "imageOut = imager.evtlist2image(\n",
    "    \"/home/laurel/astro/testing/test.fits.gz\",\"/home/laurel/astro/testing/test_reconstruct.fits.gz\"\n",
    ")\n",
    "imager.plotSource(imageOut)\n",
    "peaks = imager.imager.findpeaks(imageOut.data.T) # Index 5 has the significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feec3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = fits.open(\"/scratch/ajo5182/psfSamples/image_reconstruction/BC057_Ti_FF_233_HORI_15_0_samp1.fits.gz\")\n",
    "d2 = fits.open(\"/scratch/ajo5182/psfSamples/image_reconstruction/BC057_Ti_FF_233_HORI_15_0_samp2.fits.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14416bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test,cov1 = analyze_localization(d1,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2,cov2 = analyze_localization(d2,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = analyze_localization_directory(\"/home/laurel/astro/testing/test_reconstruct.fits.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.DataFrame.from_dict(test,orient= 'index')\n",
    "test2 = pd.DataFrame.from_dict(test2,orient= 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2155b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [None]*2\n",
    "a[0] =test\n",
    "a[1] = test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = np.empty([len(folder_list),2]) # create empty array to hold a log of stuff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeab6f2",
   "metadata": {},
   "source": [
    "for windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beedf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for windows\n",
    "fileDirectory = r\"Z:\\Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\y2024-12-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b06ec",
   "metadata": {},
   "source": [
    "for running on WSL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0baebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDirectory = r\"/mnt/z/Astro_BlackCAT/BlackCAT_Calibration_Data/LC_Calibration_Data/y2024-12-12\"\n",
    "outDirectory = r\"/mnt/z/Astro_BlackCAT/BlackCAT_Calibration_Data/LC_Calibration_Data/psfSamples\"\n",
    "splitThreshold = 550\n",
    "numberOfRandomSamples = 1500\n",
    "folder_list = [folder for folder in os.listdir(fileDirectory) if os.path.isdir(os.path.join(fileDirectory, folder))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee556b4",
   "metadata": {},
   "source": [
    "For Roar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDirectory = r\"/storage/group/adf15/default/Astro_BlackCAT/BlackCAT_Calibration_Data/LC_Calibration_Data/y2024-12-12\"\n",
    "outDirectory = r\"/scratch/ajo5182/psfSamples\" \n",
    "splitThreshold = 550\n",
    "numberOfRandomSamples = 1500\n",
    "folder_list = [folder for folder in os.listdir(fileDirectory) if os.path.isdir(os.path.join(fileDirectory, folder))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_list = [folder for folder in os.listdir(fileDirectory) if os.path.isdir(os.path.join(fileDirectory, folder))]\n",
    "\n",
    "log = [[None for _ in range(2)] for _ in range(len(folder_list))] #np.empty([len(folder_list),2],str) # empty array to log errors and wahtnot\n",
    "\n",
    "for a in range(len(folder_list)):\n",
    "    eventlistPath = Path(fileDirectory)/Path(folder_list[a])/Path(\"Analysis/imaging_analysis_20241213/combined_events_th1_200.fits.gz\")\n",
    "    try:\n",
    "        d = fits.open(eventlistPath)\n",
    "        cols = d[1].columns\n",
    "        header = d[1].header\n",
    "    \n",
    "        signal, noiseShelf = splitEventList(d,splitThreshold,\"sum\") # separate the noise shelf from the \"signal data\"\n",
    "        signal_1,signal_2 = halfEventList(signal) # split the portion of the data that is the \"signal\" in half\n",
    "\n",
    "        signal_1_random = random_sample_events_list(signal_1,numberOfRandomSamples) # take a random sample of each half of the split data\n",
    "        signal_2_random = random_sample_events_list(signal_2,numberOfRandomSamples) # take a random sample of each half of the split data\n",
    "    \n",
    "        noise = np.array(noiseShelf.data) # make a numpy array from the noise shelf data\n",
    "\n",
    "        signal_1_random.data = np.append(signal_1_random.data,noiseShelf.data) # add the noise shelf to each half of the data\n",
    "        signal_2_random.data = np.append(signal_2_random.data,noiseShelf.data) # add the noise shelf to each half of the data\n",
    "\n",
    "        signal_1_random.columns = cols\n",
    "        signal_1_random.header = header\n",
    "\n",
    "        signal_2_random.columns = cols\n",
    "        signal_2_random.header = header\n",
    "\n",
    "        signal_1_random.writeto(Path(outDirectory)/Path(folder_list[a]+\"_samp1\"+\".fits.gz\"),overwrite=True)\n",
    "        signal_2_random.writeto(Path(outDirectory)/Path(folder_list[a]+\"_samp2\"+\".fits.gz\"),overwrite=True)\n",
    "\n",
    "        #log[a,1] = folder_list[a]\n",
    "        #log[a,2] = \"created random sample files\"\n",
    "    except:\n",
    "        #log[a,0] = folder_list[a]\n",
    "        #log[a,1] = \" no file or other error\"\n",
    "        print(folder_list[a]+\" bad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a23c36",
   "metadata": {},
   "source": [
    "For WSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651d5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = fileDirectory = r\"/storage/group/adf15/default/Astro_BlackCAT/BlackCAT_Calibration_Data/LC_Calibration_Data/y2024-12-12\"\n",
    "\n",
    "image_directory= r\"/mnt/z/Astro_BlackCAT/BlackCAT_Calibration_Data/LC_Calibration_Data/psfSamples/image_reconstruction\"\n",
    "file_list = [file for file in os.listdir(data_directory) if os.path.isfile(os.path.join(data_directory, file))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d731ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(38,208)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de1210",
   "metadata": {},
   "source": [
    "For Roar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33710d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = r\"/scratch/ajo5182/psfSamples\" \n",
    "\n",
    "image_directory= r\"/scratch/ajo5182/psfSamples/image_reconstruction\"\n",
    "file_list = [file for file in os.listdir(data_directory) if os.path.isfile(os.path.join(data_directory, file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "imager= events_imaging.BC_Imaging()\n",
    "\n",
    " \n",
    "for a in range(len(file_list)): #range(len(file_list[38:208]))\n",
    "    eventlist = Path(data_directory)/Path(file_list[a])\n",
    "    image = Path(image_directory)/Path(file_list[a])\n",
    "    imageOut = imager.evtlist2image(\n",
    "        eventlist, image\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef98db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_list = sorted([file for file in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, file))])\n",
    "results_list = [None]*len(reconstruction_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfdd6e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "issue with finding peaks\n",
      "1\n",
      "issue with finding peaks\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "issue with finding peaks\n",
      "33\n",
      "issue with finding peaks\n",
      "34\n",
      "issue with finding peaks\n",
      "35\n",
      "issue with finding peaks\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "issue with finding peaks\n",
      "47\n",
      "issue with finding peaks\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "issue with finding peaks\n",
      "55\n",
      "issue with finding peaks\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "issue with finding peaks\n",
      "63\n",
      "issue with finding peaks\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "issue with finding peaks\n",
      "71\n",
      "issue with finding peaks\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "issue with finding peaks\n",
      "79\n",
      "issue with finding peaks\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "issue with finding peaks\n",
      "87\n",
      "issue with finding peaks\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "issue with finding peaks\n",
      "131\n",
      "issue with finding peaks\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "issue with finding peaks\n",
      "177\n",
      "issue with finding peaks\n",
      "178\n",
      "179\n",
      "180\n",
      "issue with finding peaks\n",
      "181\n",
      "issue with finding peaks\n",
      "182\n",
      "issue with finding peaks\n",
      "183\n",
      "issue with finding peaks\n",
      "184\n",
      "185\n",
      "186\n",
      "issue with finding peaks\n",
      "187\n",
      "issue with finding peaks\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "issue with finding peaks\n",
      "193\n",
      "issue with finding peaks\n",
      "194\n",
      "195\n",
      "issue with finding peaks\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n"
     ]
    }
   ],
   "source": [
    "for a in range(len(reconstruction_list)):\n",
    "    eventlistPath = Path(image_directory)/Path(reconstruction_list[a])\n",
    "    d = fits.open(eventlistPath)\n",
    "    print(a)\n",
    "    results_list[a] = analyze_localization(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ce57ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pickle.dump(results_list, \u001b[33m\"\u001b[39m\u001b[33mgaussfit_9-22.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "pickle.dump(results_list, \"gaussfit_9-22.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95835415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_list)\n",
    "df.to_pickle(\"gaussfit_9-22.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4574dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = pickle.load(\u001b[33m\"\u001b[39m\u001b[33mgaussfit_9-22.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "result = pickle.load(\"gaussfit_9-22.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b191338",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = sorted(reconstruction_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
