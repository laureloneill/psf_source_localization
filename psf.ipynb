{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de28d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.modeling import models, fitting\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "from shapely import LineString, MultiPoint, Polygon, centroid\n",
    "import pandas as pd\n",
    "from fitsutil import subsample_eventlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686834da",
   "metadata": {},
   "source": [
    "This code retrieves the significance of the peak from the JSON file created by bc_imaging_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6e3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peaksig_json(json_path):\n",
    "    with open(json_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    peaksig = json_data[\"peaksig\"]\n",
    "\n",
    "    return peaksig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89f364",
   "metadata": {},
   "source": [
    "The code below takes a 2D array and fits a gaussian to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85b6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rotated_2d_gaussian(data, x=None, y=None, plot_result=False,iter = None):\n",
    "    \"\"\"\n",
    "    Fit a rotated 2D Gaussian to 2D data using Astropy's Gaussian2D model.\n",
    "\n",
    "    Parameters:\n",
    "        data : 2D numpy array\n",
    "            The input data array to fit.\n",
    "        x, y : 2D numpy arrays, optional\n",
    "            Meshgrid coordinates corresponding to data. If None, will be auto-generated.\n",
    "        plot_result : bool\n",
    "            Whether to plot the original data and fit result.\n",
    "\n",
    "    Returns:\n",
    "        fitted_model : Gaussian2D\n",
    "            The best-fit Gaussian2D model.\n",
    "    \"\"\"\n",
    "    # Generate coordinate grids if not provided\n",
    "    ny, nx = data.shape\n",
    "    if x is None or y is None:\n",
    "        y, x = np.mgrid[:ny, :nx]\n",
    "\n",
    "    # Estimate initial parameters\n",
    "    amplitude_init = np.max(data)\n",
    "    x_mean_init = x[data == amplitude_init][0]\n",
    "    y_mean_init = y[data == amplitude_init][0]\n",
    "\n",
    "    # Initial guess for model\n",
    "    gauss_init = models.Gaussian2D(amplitude=amplitude_init, x_mean=x_mean_init,\n",
    "                                   y_mean=y_mean_init, x_stddev=0.089, y_stddev=0.069, theta=0)\n",
    "\n",
    "    # Fitting with Levenberg-Marquardt algorithm\n",
    "    fitter = fitting.LevMarLSQFitter()\n",
    "    fitted_model = fitter(gauss_init, x, y, data)\n",
    "    covariance_matrix = fitter.fit_info['param_cov']\n",
    "    if fitted_model.x_fwhm > 1 or fitted_model.y_fwhm >1 :\n",
    "        print(iter)\n",
    "\n",
    "    if plot_result:\n",
    "        fit_data = fitted_model(x, y)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axes[0].imshow(data, origin='lower', cmap='viridis')\n",
    "        axes[0].set_title(\"Original Data\")\n",
    "        axes[1].imshow(fit_data, origin='lower', cmap='viridis')\n",
    "        axes[1].set_title(\"Fitted Gaussian\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return fitted_model,covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_localization_nested(data_dir,window=10):\n",
    "    data_dir = Path(data_dir)\n",
    "    # take the names of all folders within the specified directory\n",
    "    folder_list = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]\n",
    "    \n",
    "    # create a bunch of empty arrays \n",
    "    run = [None]*len(folder_list)\n",
    "    anode = [None]*len(folder_list)\n",
    "    detectorMode= [None]*len(folder_list)\n",
    "    temp = [None]*len(folder_list)\n",
    "    sweep = [None]*len(folder_list)\n",
    "    vTheta = [None]*len(folder_list)\n",
    "    hTheta = [None]*len(folder_list)\n",
    "    '''\n",
    "    theta = []\n",
    "    xMean = []\n",
    "    yMean =[]\n",
    "    xSigma = []\n",
    "    ySigma = []\n",
    "    Amplitude = []\n",
    "    peakSig = []\n",
    "    cov = []\n",
    "    validPeak = []\n",
    "    pval = [] \n",
    "\n",
    "    '''\n",
    "    theta = [None]*len(folder_list)\n",
    "    xMean = [None]*len(folder_list)\n",
    "    yMean =[None]*len(folder_list)\n",
    "    xSigma = [None]*len(folder_list)\n",
    "    ySigma = [None]*len(folder_list)\n",
    "    Amplitude = [None]*len(folder_list)\n",
    "    peakSig = [None]*len(folder_list)\n",
    "    cov = [None]*len(folder_list)\n",
    "    validPeak = [None]*len(folder_list)\n",
    "    pval = [np.nan]*len(folder_list) \n",
    "    \n",
    "    for a in range(len(folder_list)): \n",
    "        numTerms = len(folder_list[a].split('_'))\n",
    "        if numTerms == 7:\n",
    "            run[a], anode[a], detectorMode[a], temp[a], sweep[a], vTheta[a], hTheta[a] =  folder_list[a].split('_')\n",
    "\n",
    "        elif numTerms == 6:\n",
    "            run[a], anode[a], detectorMode[a], temp[a], sweep[a], vTheta[a] = folder_list[a].split('_')\n",
    "            vTheta[a] = 'NA'\n",
    "            hTheta[a] = 'NA'\n",
    "        elif numTerms == 4:\n",
    "            run[a], anode[a], detectorMode[a], temp[a] = folder_list[a].split('_') \n",
    "        elif numTerms == 3:\n",
    "            run[a],vTheta[a], hTheta[a] = folder_list[a].split('_')\n",
    "\n",
    "        # Iterate through the subsample folders within the main data directory        \n",
    "        subsample_folder_list = [folder for folder in os.listdir(data_dir/Path(folder_list[a])) if os.path.isdir(os.path.join(data_dir/Path(folder_list[a]), folder))]\n",
    "        for b in range(len(subsample_folder_list)):\n",
    "            if os.path.isfile(f\"{data_dir}/{folder_list[a]}/{subsample_folder_list[b]}/Analysis/imaging_analysis_20241217/Figures/imaging_source.png\"):\n",
    "                subdata_path =  Path(f\"{data_dir}/{Path(folder_list[a])}/{Path(subsample_folder_list[b])}/Analysis/imaging_analysis_20241217/image_reconstruction.fits.gz\")\n",
    "                try:\n",
    "                    d = fits.open(subdata_path) # open fits file\n",
    "        \n",
    "                    data = d[0].data # data contents of the fits file\n",
    "\n",
    "                    ny, nx = data.shape\n",
    "                    ym, xm = np.mgrid[:ny, :nx]\n",
    "\n",
    "                    w = WCS(d[0].header)\n",
    "\n",
    "                    x,y= w.array_index_to_world_values(ym,xm)\n",
    "                    x = (x+(180+360)) % 360 -180\n",
    "\n",
    "                    peak = np.max(data)\n",
    "                    peak_loc = np.unravel_index(np.argmax(data),data.shape)\n",
    "\n",
    "\n",
    "                    windowed_data = data[peak_loc[0]-window:peak_loc[0]+window, peak_loc[1]-window:peak_loc[1]+window]\n",
    "                    x_window = x[peak_loc[0]-window:peak_loc[0]+window, peak_loc[1]-window:peak_loc[1]+window]\n",
    "                    y_window = y[peak_loc[0]-window:peak_loc[0]+window, peak_loc[1]-window:peak_loc[1]+window]\n",
    "            \n",
    "\n",
    "                    shapiro_result = stats.shapiro(windowed_data, axis=0)\n",
    "                    pval[a] = np.mean(shapiro_result.pvalue)\n",
    "\n",
    "                    fitted,covariance_matrix = fit_rotated_2d_gaussian(windowed_data, x_window, y_window, plot_result=False,iter=subsample_folder_list[a])\n",
    "\n",
    "                    validPeak[a] = True\n",
    "                    xMean[a] = fitted.x_mean.value\n",
    "                    yMean[a] = fitted.y_mean.value\n",
    "                    xSigma[a] = fitted.x_stddev.value\n",
    "                    ySigma[a] = fitted.y_stddev.value\n",
    "                    Amplitude[a] = fitted.amplitude.value\n",
    "                    theta[a] =fitted.theta.value\n",
    "                    cov[a] = covariance_matrix\n",
    "                    runout = run[a]+anode[a]+detectorMode[a]+sweep[a]+hTheta[a]+vTheta[a]\n",
    "                except:\n",
    "                    validPeak[a] = \"corrupt Fits\"\n",
    "            else:\n",
    "                validPeak[a] = False  \n",
    "            if os.path.isfile(f\"{data_dir}/{Path(folder_list[a])}/Analysis/imaging_analysis_20241217/analysis_results.json\"):\n",
    "                json_path = Path(f\"{data_dir}/{Path(folder_list[a])}/Analysis/imaging_analysis_20241217/analysis_results.json\")\n",
    "                try:\n",
    "                    peakSig[a] = get_peaksig_json(json_path)\n",
    "                except:\n",
    "                    print('no peak')\n",
    "    result = {\n",
    "        \"xCenter\" : xMean,\n",
    "        \"yCenter\" : yMean,\n",
    "        \"xSigma\" : xSigma,\n",
    "        \"ySigma\" : ySigma,\n",
    "        \"peak\" : Amplitude,\n",
    "        \"peakSig\" : peakSig,\n",
    "        \"theta\" : theta,\n",
    "        'covMatrix' : cov\n",
    "    }\n",
    "\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd46e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distFromCentroid(observation,plotHist=False):\n",
    "    # computes the centroid of a finite set of points, and returns the distance that each point is from that centroid\n",
    "    # observation -> pandas data frame consisting of the data from fitting a gaussian \n",
    "    \n",
    "    xCoord = observation['xCenter'].to_numpy(dtype = np.float32)\n",
    "    yCoord = observation['yCenter'].to_numpy(dtype = np.float32)\n",
    "\n",
    "    centroidX = np.mean(xCoord)\n",
    "    centroidY= np.mean(yCoord)\n",
    "    dist = np.sqrt((centroidX-xCoord)**2+(centroidY-yCoord)**2)\n",
    "    if plotHist == True:\n",
    "        plt.hist(dist)\n",
    "    return dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8c7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_localization(data_dir,window=10):\n",
    "    data_dir = Path(data_dir)\n",
    "    # take the names of all folders within the specified directory\n",
    "    folder_list = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]\n",
    "\n",
    "    theta = [None]*len(folder_list)\n",
    "    xMean = [None]*len(folder_list)\n",
    "    yMean =[None]*len(folder_list)\n",
    "    xSigma = [None]*len(folder_list)\n",
    "    ySigma = [None]*len(folder_list)\n",
    "    Amplitude = [None]*len(folder_list)\n",
    "    peakSig = [None]*len(folder_list)\n",
    "    cov = [None]*len(folder_list)\n",
    "    validPeak = [None]*len(folder_list)\n",
    "    pval = [np.nan]*len(folder_list) \n",
    "\n",
    "    for a in range(len(folder_list)): \n",
    "        numTerms = len(folder_list[a].split('_'))\n",
    "        if numTerms == 7:\n",
    "            run[a], anode[a], detectorMode[a], temp[a], sweep[a], vTheta[a], hTheta[a] =  folder_list[a].split('_')\n",
    "\n",
    "        elif numTerms == 6:\n",
    "            run[a], anode[a], detectorMode[a], temp[a], sweep[a], vTheta[a] = folder_list[a].split('_')\n",
    "            vTheta[a] = 'NA'\n",
    "            hTheta[a] = 'NA'\n",
    "        elif numTerms == 4:\n",
    "            run[a], anode[a], detectorMode[a], temp[a] = folder_list[a].split('_') \n",
    "        elif numTerms == 3:\n",
    "            run[a],vTheta[a], hTheta[a] = folder_list[a].split('_')\n",
    "        if os.path.isfile(f\"{data_dir}/{folder_list[a]}/Analysis/imaging_analysis/Figures/imaging_source.png\"):\n",
    "            data_path = Path(f\"{data_dir}/{folder_list[a]}/Analysis/imaging_analysis/image_reconstruction.fits.gz\")\n",
    "            try:\n",
    "                d = fits.open(data_path) # open fits file\n",
    "        \n",
    "                data = d[0].data # data contents of the fits file\n",
    "            #shape =  data.shape\n",
    "\n",
    "                ny, nx = data.shape\n",
    "                ym, xm = np.mgrid[:ny, :nx]\n",
    "\n",
    "                w = WCS(d[0].header)\n",
    "\n",
    "                x,y= w.array_index_to_world_values(ym,xm)\n",
    "                x = (x+(180+360)) % 360 -180\n",
    "\n",
    "                peak = np.max(data)\n",
    "                peak_loc = np.unravel_index(np.argmax(data),data.shape)\n",
    "                window = 10\n",
    "\n",
    "                windowed_data = data[peak_loc[0]-window:peak_loc[0]+window, peak_loc[1]-window:peak_loc[1]+window]\n",
    "                x_window = x[peak_loc[0]-window:peak_loc[0]+window, peak_loc[1]-window:peak_loc[1]+window]\n",
    "                y_window = y[peak_loc[0]-window:peak_loc[0]+window, peak_loc[1]-window:peak_loc[1]+window]\n",
    "\n",
    "                fitted,covariance_matrix = fit_rotated_2d_gaussian(windowed_data, x_window, y_window, plot_result=False,iter=folder_list[a])\n",
    "        \n",
    "                validPeak[a] = True\n",
    "                xMean[a] = fitted.x_mean.value\n",
    "                yMean[a] = fitted.y_mean.value\n",
    "                xSigma[a] = fitted.x_stddev.value\n",
    "                ySigma[a] = fitted.y_stddev.value\n",
    "                Amplitude[a] = fitted.amplitude.value\n",
    "                theta[a] =fitted.theta.value\n",
    "                cov[a] = covariance_matrix\n",
    "            except:\n",
    "                validPeak[a] = \"corrupt Fits\"\n",
    "        else:\n",
    "            validPeak[a] = False  \n",
    "        if os.path.isfile(f\"{data_dir}/{folder_list[a]}/Analysis/imaging_analysis/analysis_results.json\"):\n",
    "            json_path = Path(f\"{data_dir}/{folder_list[a]}/Analysis/imaging_analysis/analysis_results.json\")\n",
    "            try:\n",
    "                peakSig[a] = get_peaksig_json(json_path)\n",
    "            except:\n",
    "                print('no peak')\n",
    "    result = {\n",
    "        \"xCenter\" : xMean,\n",
    "        \"yCenter\" : yMean,\n",
    "        \"xSigma\" : xSigma,\n",
    "        \"ySigma\" : ySigma,\n",
    "        \"peak\" : Amplitude,\n",
    "        \"peakSig\" : peakSig,\n",
    "        \"theta\" : theta,\n",
    "        'covMatrix' : cov\n",
    "    }\n",
    "\n",
    "    result = pd.DataFrame(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea64ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no peak\n"
     ]
    }
   ],
   "source": [
    "BC001_Al_FF_243K_HORI_0_0 = analyze_localization(r\"Z:\\Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\Raw Long Cell Data\\subsampled_eventlists\\BC001_Al_FF_243K_HORI_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0913da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subsample_eventlist(\n",
    "    \"Z:\\Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\Raw Long Cell Data\\y2024-12-09\\BC001_Al_FF_243K_HORI_0_0\\output\",\n",
    "    2,\n",
    "    \"Z:\\Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\Raw Long Cell Data\\subsampled_eventlists\\test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3426b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"Z:\\Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\Raw Long Cell Data\\y2024-12-09\\BC001_Al_FF_243K_HORI_0_0\\output\"\n",
    "outdir =     r\"Z:\\Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\Raw Long Cell Data\\subsampled_eventlists\\BC001_Al_FF_243K_HORI_0_0\"\n",
    "numberOfLists = 10\n",
    "runname = \"BC001_Al_FF_243K_HORI_0_0\"\n",
    "\n",
    "file_list = [file for file in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, file))] \n",
    "os.mkdir(outdir)\n",
    "for a in range(len(file_list)):\n",
    "    d = fits.open(data_dir/Path(file_list[a]))\n",
    "    data = d[1].data \n",
    "    cols = d[1].columns\n",
    "    size = len(data)\n",
    "    numberOfSamples = int(size/numberOfLists)\n",
    "    subSampleHDU = fits.BinTableHDU.from_columns(cols)\n",
    "    for n in range(numberOfLists):\n",
    "        subSampleHDU.data = d[1].data[n*numberOfSamples:(n+1)*numberOfSamples]\n",
    "        out = outdir/Path('subsample'+str(n))\n",
    "        if os.path.isdir((out)) == False:\n",
    "            os.mkdir(out)\n",
    "                #print('made the directory')\n",
    "            #else:\n",
    "            #    print(\"didn't make the directory\")\n",
    "\n",
    "        subSampleHDU.writeto(out/Path(file_list[a]),overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668d08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [None,None,None]\n",
    "params[1] = BC001_Al_FF_243K_HORI_10_0\n",
    "test = {\n",
    "    \"name\": \"BC001_Al_FF_243K_HORI_10_0\",\n",
    "    \"params\":params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e28239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no peak\n",
      "no peak\n",
      "no peak\n",
      "no peak\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(r\"Z:\\Astro_BlackCAT\\BlackCAT_Calibration_Data\\LC_Calibration_Data\\Raw Long Cell Data\\subsampled_eventlists\")\n",
    "\n",
    "folder_list = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]\n",
    "\n",
    "params = [None]*len(folder_list)\n",
    "\n",
    "for a in range(len(folder_list)):\n",
    "    analysisDir = data_dir/Path(folder_list[a])\n",
    "    params[a] = analyze_localization(analysisDir)\n",
    "\n",
    "results = {\n",
    "    \"names\" : folder_list,\n",
    "    \"params\" : params \n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16825235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[  xCenter yCenter xSigma ySigma  peak peakSig theta covMatrix\n",
       " 0    None    None   None   None  None    None  None      None\n",
       " 1    None    None   None   None  None    None  None      None\n",
       " 2    None    None   None   None  None    None  None      None\n",
       " 3    None    None   None   None  None    None  None      None\n",
       " 4    None    None   None   None  None    None  None      None\n",
       " 5    None    None   None   None  None    None  None      None\n",
       " 6    None    None   None   None  None    None  None      None\n",
       " 7    None    None   None   None  None    None  None      None\n",
       " 8    None    None   None   None  None    None  None      None\n",
       " 9    None    None   None   None  None    None  None      None,\n",
       "      xCenter   yCenter    xSigma    ySigma         peak    peakSig     theta  \\\n",
       " 0 -10.028719  1.491188  0.083928  0.067705  1645.967125  13.930698 -0.410362   \n",
       " 1        NaN       NaN       NaN       NaN          NaN  12.364029       NaN   \n",
       " 2        NaN       NaN       NaN       NaN          NaN  11.324035       NaN   \n",
       " 3        NaN       NaN       NaN       NaN          NaN  12.215332       NaN   \n",
       " 4        NaN       NaN       NaN       NaN          NaN  13.563220       NaN   \n",
       " 5        NaN       NaN       NaN       NaN          NaN  11.978355       NaN   \n",
       " 6        NaN       NaN       NaN       NaN          NaN  12.537462       NaN   \n",
       " 7        NaN       NaN       NaN       NaN          NaN  12.521647       NaN   \n",
       " 8        NaN       NaN       NaN       NaN          NaN  11.779349       NaN   \n",
       " 9        NaN       NaN       NaN       NaN          NaN  12.948036       NaN   \n",
       " \n",
       "                                            covMatrix  \n",
       " 0  [[3117.0228362077887, 5.917332239847617e-05, -...  \n",
       " 1                                               None  \n",
       " 2                                               None  \n",
       " 3                                               None  \n",
       " 4                                               None  \n",
       " 5                                               None  \n",
       " 6                                               None  \n",
       " 7                                               None  \n",
       " 8                                               None  \n",
       " 9                                               None  ,\n",
       "   xCenter yCenter xSigma ySigma  peak peakSig theta covMatrix\n",
       " 0    None    None   None   None  None    None  None      None\n",
       " 1    None    None   None   None  None    None  None      None\n",
       " 2    None    None   None   None  None    None  None      None\n",
       " 3    None    None   None   None  None    None  None      None\n",
       " 4    None    None   None   None  None    None  None      None\n",
       " 5    None    None   None   None  None    None  None      None\n",
       " 6    None    None   None   None  None    None  None      None\n",
       " 7    None    None   None   None  None    None  None      None\n",
       " 8    None    None   None   None  None    None  None      None\n",
       " 9    None    None   None   None  None    None  None      None,\n",
       "   xCenter yCenter xSigma ySigma  peak peakSig theta covMatrix\n",
       " 0    None    None   None   None  None    None  None      None\n",
       " 1    None    None   None   None  None    None  None      None\n",
       " 2    None    None   None   None  None    None  None      None\n",
       " 3    None    None   None   None  None    None  None      None\n",
       " 4    None    None   None   None  None    None  None      None\n",
       " 5    None    None   None   None  None    None  None      None\n",
       " 6    None    None   None   None  None    None  None      None\n",
       " 7    None    None   None   None  None    None  None      None\n",
       " 8    None    None   None   None  None    None  None      None\n",
       " 9    None    None   None   None  None    None  None      None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"params\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
